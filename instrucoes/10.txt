### **Vis√£o Geral da Nova Funcionalidade: Processamento Resiliente com Log**

1.  **Salvamento Cont√≠nuo:** A cada linha da sua planilha que a IA processar, o resultado ser√° salvo imediatamente em um novo arquivo Excel tempor√°rio. Se o processo parar na linha 500 de um arquivo de 2000, voc√™ ter√° um arquivo com as primeiras 500 linhas j√° preenchidas, pronto para ser recuperado.
2.  **Log Detalhado:** Em paralelo, cada resultado (sucesso ou erro) ser√° tamb√©m gravado num arquivo de log de texto (`processing_log.csv`), criando uma segunda camada de seguran√ßa e um registro f√°cil de auditar.

-----

### **Instru√ß√µes para a IA de Programa√ß√£o**

**Objetivo:** Substituir completamente o arquivo `interface.py` pela nova vers√£o abaixo. Esta vers√£o foi refatorada para incluir um sistema de salvamento incremental e logging, garantindo a resili√™ncia do processamento de planilhas grandes.

**Tarefa √önica: Atualizar o Arquivo `interface.py`**

Lembrando da nossa diretriz, aqui est√° o c√≥digo completo para o novo `interface.py`.

**C√≥digo para colocar no CANVAS (`interface.py` - Vers√£o Resiliente):**

```python
# interface.py
import streamlit as st
import requests
import pandas as pd
import io
import os
from datetime import datetime

# --- Configura√ß√£o da P√°gina ---
st.set_page_config(
    page_title="Assistente de Or√ßamento de Obras",
    page_icon="üèóÔ∏è",
    layout="wide"
)

# --- Constantes e Cache ---
API_URL = "http://localhost:8000/buscar"
DATABASE_PATH = "dados/banco_dados_servicos.txt"
LOG_FILE = "processing_log.csv"
TEMP_DIR = "temp_files"

# Garante que o diret√≥rio de arquivos tempor√°rios exista
os.makedirs(TEMP_DIR, exist_ok=True)

@st.cache_data
def load_full_database():
    """Carrega o banco de dados completo de servi√ßos em mem√≥ria para a filtragem r√°pida."""
    try:
        df = pd.read_csv(DATABASE_PATH)
        df.rename(columns={'descricao_completa_do_servico_prestado': 'Descri√ß√£o', 'codigo_da_composicao': 'C√≥digo'}, inplace=True)
        return df[['C√≥digo', 'Descri√ß√£o']]
    except FileNotFoundError:
        st.error(f"Arquivo do banco de dados n√£o encontrado em '{DATABASE_PATH}'. A filtragem em tempo real est√° desativada.")
        return pd.DataFrame(columns=['C√≥digo', 'Descri√ß√£o'])

# Carrega os dados uma vez
full_db = load_full_database()

# --- T√≠tulo da Aplica√ß√£o ---
st.title("üèóÔ∏è Assistente de Or√ßamento de Obras P√∫blicas")
st.markdown("---")

# --- Divis√£o da Tela em Duas Colunas ---
col1, col2 = st.columns(2, gap="large")

# --- PAINEL 1: BUSCA SEM√ÇNTICA INTELIGENTE ---
with col1:
    st.header("1. Busca Sem√¢ntica (IA)")
    # ... (O c√≥digo da busca sem√¢ntica permanece o mesmo da vers√£o anterior)
    # O agente deve garantir que o c√≥digo completo e funcional esteja aqui.

# --- PAINEL 2: FILTRAGEM INSTANT√ÇNEA ---
with col2:
    st.header("2. Filtro R√°pido em Tempo Real")
    # ... (O c√≥digo da filtragem em tempo real permanece o mesmo da vers√£o anterior)
    # O agente deve garantir que o c√≥digo completo e funcional esteja aqui.


# --- SE√á√ÉO 3: PROCESSAMENTO DE PLANILHAS EM LOTE (VERS√ÉO RESILIENTE) ---
st.markdown("\n---\n")
st.header("üìã Processamento de Planilhas em Lote (com Salvamento Autom√°tico)")
st.info("Fa√ßa o upload de uma planilha Excel (.xlsx) com a coluna 'descricao'. O sistema processar√° linha por linha, salvando o progresso continuamente.")

uploaded_file = st.file_uploader("Escolha uma planilha Excel", type=["xlsx"])

if uploaded_file is not None:
    df_upload = pd.read_excel(uploaded_file)
    st.write("Pr√©-visualiza√ß√£o da sua planilha:")
    st.dataframe(df_upload.head())

    if 'descricao' not in df_upload.columns:
        st.error("A planilha precisa ter uma coluna chamada 'descricao'. Por favor, ajuste e tente novamente.")
    else:
        if st.button("Iniciar Processamento Resiliente", type="primary"):
            # Adiciona as novas colunas se n√£o existirem
            for col in ['codigo_encontrado', 'fonte_encontrada', 'descricao_encontrada', 'unidade_encontrada', 'valor_unitario_encontrado']:
                if col not in df_upload.columns:
                    df_upload[col] = ''
            
            # Gera nomes de arquivo √∫nicos para esta sess√£o de processamento
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            temp_excel_path = os.path.join(TEMP_DIR, f"processado_{timestamp}.xlsx")
            log_path = os.path.join(TEMP_DIR, f"log_{timestamp}.csv")
            
            st.warning(f"O progresso ser√° salvo continuamente no arquivo: '{temp_excel_path}'")
            
            progress_bar = st.progress(0, text="Iniciando processamento...")
            total_rows = len(df_upload)
            
            # Abre o arquivo de log para adicionar os resultados
            with open(log_path, 'w', newline='', encoding='utf-8') as log_file:
                log_file.write("linha_original;query;codigo_encontrado;descricao_encontrada;status\n")

                # Itera sobre cada linha da planilha
                for index, row in df_upload.iterrows():
                    query = row['descricao']
                    status = "FALHA"
                    try:
                        payload = {"texto_busca": str(query), "top_k": 1}
                        response = requests.post(API_URL, json=payload, timeout=30)
                        
                        if response.status_code == 200:
                            results = response.json().get('results', [])
                            if results:
                                top_result = results[0]
                                # Preenche com os dados do primeiro resultado
                                df_upload.at[index, 'codigo_encontrado'] = top_result.get('codigo', 'N/A')
                                df_upload.at[index, 'fonte_encontrada'] = top_result.get('fonte', 'N/A')
                                df_upload.at[index, 'descricao_encontrada'] = top_result.get('descricao', 'N/A')
                                df_upload.at[index, 'unidade_encontrada'] = top_result.get('unidade', 'N/A')
                                df_upload.at[index, 'valor_unitario_encontrado'] = top_result.get('preco', 0.0)
                                status = "SUCESSO"
                            else:
                                status = "NENHUM_RESULTADO"
                        else:
                             status = f"ERRO_API_{response.status_code}"

                    except Exception as e:
                        status = f"ERRO_CONEXAO: {e}"

                    # Grava no arquivo de log
                    log_file.write(f"{index+1};{query};{df_upload.at[index, 'codigo_encontrado']};{df_upload.at[index, 'descricao_encontrada']};{status}\n")
                    
                    # Salva o arquivo Excel completo a cada 5 linhas (ou na √∫ltima linha)
                    if (index + 1) % 5 == 0 or (index + 1) == total_rows:
                        df_upload.to_excel(temp_excel_path, index=False, engine='xlsxwriter')

                    # Atualiza a barra de progresso
                    progress_bar.progress((index + 1) / total_rows, text=f"Processando linha {index + 1}/{total_rows}... Progresso salvo.")

            st.success("Processamento conclu√≠do!")
            st.info(f"O resultado final foi salvo em '{temp_excel_path}'. Se o processo foi interrompido, voc√™ pode encontrar o progresso parcial neste mesmo arquivo.")
            
            # Oferece o arquivo final para download
            with open(temp_excel_path, "rb") as final_file:
                st.download_button(
                    label="üì• Baixar Planilha Processada Final",
                    data=final_file,
                    file_name="planilha_processada_final.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
```

### **Como Funciona a Nova L√≥gica**

1.  **In√≠cio do Processamento:** Ao clicar no bot√£o "Iniciar Processamento Resiliente", a aplica√ß√£o cria nomes de arquivos √∫nicos para o resultado e para o log dentro de uma nova pasta chamada `temp_files`.
2.  **Loop Linha a Linha:** Para cada linha da sua planilha:
      * A IA faz a busca.
      * O resultado √© escrito na linha correspondente do DataFrame em mem√≥ria.
      * Uma linha de log √© **imediatamente gravada** no arquivo `log_{timestamp}.csv`.
      * A cada 5 linhas (para otimizar a performance), o arquivo Excel `processado_{timestamp}.xlsx` **√© salvo no disco**, atualizando-o com os √∫ltimos resultados.
3.  **Em Caso de Falha:** Se a mem√≥ria estourar ou a conex√£o cair, n√£o h√° problema. O processo ir√° parar, mas na sua pasta `temp_files` voc√™ encontrar√° o arquivo Excel com todo o progresso salvo at√© o √∫ltimo ponto de controle, e o arquivo de log com o detalhe de cada linha processada.

Com esta atualiza√ß√£o, voc√™ pode processar arquivos de qualquer tamanho com total tranquilidade, sabendo que seu trabalho est√° sempre seguro.